{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "64e7f88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words(\"english\")\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "from nltk.tokenize import sent_tokenize,word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "import json\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from skmultilearn.problem_transform import BinaryRelevance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f0d376",
   "metadata": {},
   "source": [
    "<h3>Function: Cleaning the corpus</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6383a766",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \n",
    "    # To lower case\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove new line characters\n",
    "    text = text.replace(\"\\t\",\" \")\n",
    "    text = text.replace(\"\\n\",\" \")\n",
    "    \n",
    "    # Remove punctuation\n",
    "    text = re.sub(r\"[^\\w\\s]\", \" \", text)\n",
    "    \n",
    "    # Remove digits\n",
    "    text = re.sub(r\"\\b\\d+\\b\",\" \", text)\n",
    "    \n",
    "    # Remove multiple white spaces\n",
    "    text = re.sub(r' +', ' ', text)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    text = [x for x in text.split() if x not in stop]\n",
    "    \n",
    "    # Stemming (Did not use)\n",
    "    # text = [stemmer.stem(x) for x in text]\n",
    "    \n",
    "    return \" \".join(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d963aac",
   "metadata": {},
   "source": [
    "<h3>Clean the corpus</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7f463b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, rows in movie_subset.iterrows():\n",
    "    movie_subset.loc[index,'plot'] = clean_text(movie_subset.loc[index,'plot'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14744153",
   "metadata": {},
   "source": [
    "<h3>Read the dataset</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f8e03f5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22559, 4)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie = pd.read_csv(\"../scripts/movie_cleaned.csv\", sep=\"\\t\")\n",
    "movie.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a37901",
   "metadata": {},
   "source": [
    "<h3>Binarize labels</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c3b2d42e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "labels_list = []\n",
    "for index, rows in movie.iterrows():\n",
    "    labels = rows['genres'].split(\",\")\n",
    "    labels_list.append(labels)\n",
    "labels = mlb.fit_transform(labels_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f6bb13",
   "metadata": {},
   "source": [
    "<h3>Sanity check</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8d81de53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22559, 16)\n",
      "['Action Adventure', 'Animation', 'Comedy', 'Crime', 'Drama', 'Family Film', 'Fantasy', 'Horror', 'Mystery', 'Period piece', 'Romance', 'Science Fiction', 'Thriller', 'War film', 'Western', 'World cinema']\n",
      "[1 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0]\n",
      "['Action Adventure', 'Science Fiction', 'Thriller', 'Horror']\n"
     ]
    }
   ],
   "source": [
    "print(labels.shape)\n",
    "all_genres = list(mlb.classes_)\n",
    "print(all_genres)\n",
    "print(labels[0])\n",
    "print(labels_list[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b45265e",
   "metadata": {},
   "source": [
    "<h3>Ten-fold cross validation</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c0023ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_subset = movie.loc[:19999]\n",
    "kf = KFold(n_splits=10, shuffle=False)\n",
    "indices = np.array(movie_subset.index)\n",
    "\n",
    "list_train_index = []\n",
    "list_test_index = []\n",
    "\n",
    "for train_index, test_index in kf.split(indices):\n",
    "    list_train_index.append(train_index)\n",
    "    list_test_index.append(test_index)\n",
    "\n",
    "# Sanity check: Should have 10 sets of training and testing data\n",
    "assert len(list_train_index) == len(list_test_index) == 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75876fca",
   "metadata": {},
   "source": [
    "<h3>Train individual logistic regression model for each genre</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6dbca483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running on fold  1\n",
      "running on fold  2\n",
      "running on fold  3\n",
      "running on fold  4\n",
      "running on fold  5\n",
      "running on fold  6\n",
      "running on fold  7\n",
      "running on fold  8\n",
      "running on fold  9\n",
      "running on fold  10\n"
     ]
    }
   ],
   "source": [
    "predicted_results = []\n",
    "ground_truth = []\n",
    "\n",
    "for i in range(0, 10):\n",
    "    \n",
    "    # Get the text\n",
    "    training_data_index = list_train_index[i]\n",
    "    testing_data_index = list_test_index[i]\n",
    "    training_data = movie_subset.loc[movie_subset.index.isin(training_data_index)]\n",
    "    testing_data  = movie_subset.loc[movie_subset.index.isin(testing_data_index)]\n",
    "    \n",
    "    # Build tf-idf vectors for training data\n",
    "    tfidf_vectorizer = TfidfVectorizer(lowercase=True, min_df=0.005, ngram_range=(1, 1), max_df=0.9)\n",
    "    tfidf_matrix_train = tfidf_vectorizer.fit_transform(training_data['plot'])\n",
    "    training_features = tfidf_matrix_train.toarray()\n",
    "    \n",
    "    # Get labels for training and testing\n",
    "    training_labels = labels[list_train_index[i]]\n",
    "    testing_labels = labels[list_test_index[i]]\n",
    "    \n",
    "    # Build tf-idf vectors for testing data\n",
    "    tfidf_matrix_test = tfidf_vectorizer.transform(testing_data['plot'])\n",
    "    testing_features = tfidf_matrix_test.toarray()\n",
    "    \n",
    "    # Train the classifier\n",
    "    print(\"running on fold \", i+1)\n",
    "    BinaryClassifier = BinaryRelevance(classifier=LogisticRegression(class_weight='balanced'))\n",
    "    BinaryClassifier.fit(training_features, training_labels)\n",
    "    \n",
    "    # Do the prediction\n",
    "    predicted_probs = BinaryClassifier.predict_proba(testing_features)\n",
    "    predicted_probs = predicted_probs.toarray()\n",
    "    predicted_labels = predicted_probs.copy()\n",
    "    predicted_labels[predicted_labels>=0.5] = 1\n",
    "    predicted_labels[predicted_labels<0.5] = 0\n",
    "    \n",
    "    # Track predicted labels and ground truth\n",
    "    predicted_results.append(predicted_labels)\n",
    "    ground_truth.append(testing_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff37f82",
   "metadata": {},
   "source": [
    "<h3>Calculate the percision/recall/f1 score</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "db4913a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns=['genre', 'fold_no', 'precision', 'recall', 'f1'])\n",
    " \n",
    "for fold_no in range(0, 10):\n",
    "    \n",
    "    predicted_labels = predicted_results[fold_no] # Shape = 2000, 16\n",
    "    true_labels = ground_truth[fold_no] # Shape = 2000, 16\n",
    "    \n",
    "    # Iterate over each genre\n",
    "    for genre_index in range(0, 16):\n",
    "        \n",
    "        # Fetch an array of 2000 elements for x-th genre\n",
    "        per_genre_predicted_label = predicted_labels[:, genre_index]\n",
    "        per_genre_true_label = true_labels[:, genre_index]\n",
    "        \n",
    "        # Compute\n",
    "        precision = precision_score(per_genre_true_label, per_genre_predicted_label)\n",
    "        recall = recall_score(per_genre_true_label, per_genre_predicted_label)\n",
    "        f1 = f1_score(per_genre_true_label, per_genre_predicted_label)\n",
    "        \n",
    "        genre_name = all_genres[genre_index]\n",
    "        \n",
    "        # Add to the dataframe\n",
    "        new_row = dict()\n",
    "        new_row['genre'] = genre_name\n",
    "        new_row['fold_no'] = fold_no\n",
    "        new_row['precision'] = precision\n",
    "        new_row['recall'] = recall\n",
    "        new_row['f1'] = f1\n",
    "        results = results.append(new_row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "af91a1e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action Adventure\n",
      "0.7419\n",
      "0.7519\n",
      "0.7466\n",
      "Animation\n",
      "0.7419\n",
      "0.7519\n",
      "0.7466\n",
      "Comedy\n",
      "0.7419\n",
      "0.7519\n",
      "0.7466\n",
      "Crime\n",
      "0.7419\n",
      "0.7519\n",
      "0.7466\n",
      "Drama\n",
      "0.7419\n",
      "0.7519\n",
      "0.7466\n",
      "Family Film\n",
      "0.7419\n",
      "0.7519\n",
      "0.7466\n",
      "Fantasy\n",
      "0.7419\n",
      "0.7519\n",
      "0.7466\n",
      "Horror\n",
      "0.7419\n",
      "0.7519\n",
      "0.7466\n",
      "Mystery\n",
      "0.7419\n",
      "0.7519\n",
      "0.7466\n",
      "Period piece\n",
      "0.7419\n",
      "0.7519\n",
      "0.7466\n",
      "Romance\n",
      "0.7419\n",
      "0.7519\n",
      "0.7466\n",
      "Science Fiction\n",
      "0.7419\n",
      "0.7519\n",
      "0.7466\n",
      "Thriller\n",
      "0.7419\n",
      "0.7519\n",
      "0.7466\n",
      "War film\n",
      "0.7419\n",
      "0.7519\n",
      "0.7466\n",
      "Western\n",
      "0.7419\n",
      "0.7519\n",
      "0.7466\n",
      "World cinema\n",
      "0.7419\n",
      "0.7519\n",
      "0.7466\n"
     ]
    }
   ],
   "source": [
    "for genre in all_genres:\n",
    "    print(genre)\n",
    "    results_per_genre = results.loc[results.genre==genre]\n",
    "    print(np.round(np.mean(results_per_genre['precision']), 4))\n",
    "    print(np.round(np.mean(results_per_genre['recall']), 4))\n",
    "    print(np.round(np.mean(results_per_genre['f1']), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663781d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
